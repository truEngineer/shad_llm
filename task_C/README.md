Ваша задача - написать эффективную имплементацию операцию `padded_moe_permute`.

Ваша функция должна называться `submission` и иметь следующую сигнатуру:

```
def submission(
    x: torch.Tensor,  # (num_tokens, hidden_size) - входной тензор токенов, каждый размерности hidden_size
    top_experts: torch.Tensor,  # (num_tokens, topk) - для каждого токена указано topk экспертов, которые он активирует
    tokens_per_expert: torch.Tensor, # (num_experts,) - тензор размерности числа экспертов, i-ый элемент - сколько токенов приходит в i-ого эксперта
    topk: int,  # сколько экспертов активируются на каждый токен, например, 8
    num_experts: int,  # сколько всего экспертов в MoE, например, 128
) -> tuple[
    torch.Tensor,  # (max_padded, hidden_size) - padded_tokens, результат пермьюта с паддингами
    torch.Tensor. # (num_experts,) - padded_tokens_per_expert, сколько токенов приходят в каждого эксперта вместе с паддингами
]
```

## Для начала рассмотрим стандартную функцию moe_permute без учета паддингов:

На вход permute-функции приходит тензор размерности (`num_tokens`, `hidden_size`). Обычно в MoE пермьют переставляет токены так, чтобы токены, попадающие в одного эксперта, находились друг за другом.
Например, путь на вход подается
```
x = tensor([[-0.0236, -0.5368, -0.5663],
            [ 0.7778, -0.8583, -0.1123],
            [ 0.1981, -0.3514, -0.9443],
            [-2.0655, -0.9424,  0.9870]])
top_experts = tensor([[1, 3],  # токен 0 выбирает экспертов 1 и 3
                    [2, 5],    # токен 1 выбирает 2 и 5
                    [3, 5],    # токен 2 выбирает 3 и 5
                    [2, 4]])   # токен 3 выбирает 2 и 4
```
В данном случае `topk=2`, каждый токен выбирает 2 экспертов.
Выходной тензор будет иметь размерность `(num_tokens * topk, hidden_size)`, там сначала будут записаны токены для 0ого эксперта, потом для 1ого, потом для 2ого и так далее.
В данном случае:
```
out = tensor([[-0.0236, -0.5368, -0.5663],# токен 0 -> эксперт 1
            [ 0.7778, -0.8583, -0.1123],  # токен 1 -> эксперт 2
            [-2.0655, -0.9424,  0.9870],  # токен 3 -> эксперт 2
            [-0.0236, -0.5368, -0.5663],  # токен 0 -> эксперт 3
            [ 0.1981, -0.3514, -0.9443],  # токен 2 -> эксперт 3
            [-2.0655, -0.9424,  0.9870],  # токен 3 -> эксперт 4
            [ 0.7778, -0.8583, -0.1123],  # токен 1 -> эксперт 5
            [ 0.1981, -0.3514, -0.9443]]) # токен 2 -> эксперт 5
```

**Тензор размерности (num_experts,), который показывает, сколько токенов идут в каждого эксперта, назовем батч сайзами.** В примере выше батч сайзы - это `[1, 2, 2, 1, 2]`.


## Теперь к нашей задаче

При использовании FP8-умножения из `DeepGEMM` (и других современных кернелов) часто ожидается `TMA`-алаймент тензора, то есть появляется требование делимости размерностей на 128.
Это нужно для использования `Tensor Memory Accelerator`-а на H100 для асинхронного копирования из памяти.

В случае `moe_permute` это означает необходимость делимости батч сайзов на 128, то есть чтобы в каждого эксперта приходило делящееся на 128 число токенов.
В примере выше батч сайзы `[1, 2, 2, 1, 2]` станут `[128, 128, 128, 128, 128]`. А, например, `[128, 1, 129]` перейдет в `[128, 128, 256]`.

Чтобы добиться такой гарантии, нам придется западдить результат пермьюта. Теперь он не обязательно будет иметь размерность `num_tokens * topk`, а может содержать дополнительные нулевые токены.
Ваша задача - написать функцию, которая будет делать то же самое, что и обычный `moe_permute`, но уже с паддингами - то есть дополнительно будет гарантировать, что первый токен для каждого эксперта начинается с индекса, делящегося на 128.

В случае входа из примера выше на выходе мы должны получить
```
tensor([[-0.0236, -0.5368, -0.5663], # токен 0 -> эксперт 1
        [ 0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000],
        ...,
        [ 0.7778, -0.8583, -0.1123],  # токен 1 -> эксперт 2, индекс 128
        [-2.0655, -0.9424,  0.9870],  # токен 3 -> эксперт 2, индекс 129
        [ 0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000]
        ...,
        [ 0.0000,  0.0000,  0.0000]])
```

Для имплементация можно использовать как `Triton`, так и обычный `Torch`.

Имплементация будет проверяться на корректность и производительность. Для прохождения теста на корректность результат вашей функций должен совпадать на `torch.allclose` с выходом eager-имплементации.
Для прохождения теста на производительность ваша функция должна выдавать скорость примерно совпадающую с нашей референсной имлпементацией. Наша референсная имплементация не очень эффективная, поэтому не спешите сразу начинать с `Triton`.

Для простоты вам также дан неэффективный код с `for`-ами.

## Примечание
Логи тестирования можно посмотреть, скачав вывод в тесте 1 на сайте контеста.
Не переименовывайте файл `solution.py`. Ваше решение должно быть в этом файле.