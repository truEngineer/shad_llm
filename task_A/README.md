## Условие

Ваша задача - ускорить `forward pass` функции `swiglu`:
```python
def swiglu(a, b):
    return torch.nn.functional.silu(a) * b
```

Ваша имплементация должна быть написана на `Triton`, вызываться через интерфейс `torch.ops.llm_scaling_week.swiglu_fwd(a, b)` и возвращать только один torch.Tensor - результат операции.

Имплементация будет проверяться на корректность и производительность. Для прохождения теста на корректность результат вашей функций должен совпадать на `torch.allclose` с выходом eager-имплементации `swiglu`.
Для прохождения теста на производительность ваша функция должна занимать $\le 75$% от скорости eager-имплементации `swiglu`.

**Гарантируется, что на вход будут поданы `contiguous`-тензоры. Типы и размерности входных тензоров `a` и `b` совпадают.**
Обратите внимание, что функция должна уметь работать как с `fp32`, так и с `bf16` тензорами. Функция должна уметь работать эффективно вне зависимости от размерности тензоров.

Референсное решение проходит все тесты и на H100, и в Google Colab.

## Примечание
Логи тестирования можно посмотреть, скачав вывод в тесте 1 на сайте контеста.
Не переименовывайте файл `solution.py`. Ваше решение должно быть в этом файле.